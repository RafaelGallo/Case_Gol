





# Instalando pacotes
!pip install watermark
!pip install pydotplus
!pip install catboost


# Import of libraries

# System libraries
import re
import unicodedata
import itertools

# Library for file manipulation
import pandas as pd
import numpy as np
import pandas

# Data visualization
import seaborn as sns
import matplotlib.pylab as pl
import matplotlib as m
import matplotlib as mpl
import matplotlib.pyplot as plt
import plotly.express as px
from matplotlib import pyplot as plt

# Configuration for graph width and layout
sns.set_theme(style='whitegrid')
palette='viridis'

# Warnings remove alerts
import warnings
warnings.filterwarnings("ignore")

# Python version
from platform import python_version
print('Python version in this Jupyter Notebook:', python_version())

# Load library versions
import watermark

# Library versions
%reload_ext watermark
%watermark -a "Library versions" --iversions





# Lista de URLs dos arquivos CSV
urls = ["https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/percentuais-de-atrasos-e-cancelamentos-2/2018/vra-01_2018.csv",
        "https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/percentuais-de-atrasos-e-cancelamentos-2/2018/vra-02_2018.csv",
        "https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/percentuais-de-atrasos-e-cancelamentos-2/2018/vra_032018.csv",
        "https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/percentuais-de-atrasos-e-cancelamentos-2/2018/vra_04.csv",
        "https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/percentuais-de-atrasos-e-cancelamentos-2/2018/vra_05.csv",
        "https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/percentuais-de-atrasos-e-cancelamentos-2/2018/vra_062018.csv",
        "https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/percentuais-de-atrasos-e-cancelamentos-2/2018/vra_072018.csv",
        "https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/percentuais-de-atrasos-e-cancelamentos-2/2018/vra_082018.csv",
        "https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/percentuais-de-atrasos-e-cancelamentos-2/2018/vra_092018.csv",
        "https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/percentuais-de-atrasos-e-cancelamentos-2/2018/vra_102018.csv",
        "https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/percentuais-de-atrasos-e-cancelamentos-2/2018/vra_112018.csv",
        "https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/percentuais-de-atrasos-e-cancelamentos-2/2018/vra_122018.csv"]

# Lista para armazenar os DataFrames
dataframes = []

# Loop para ler cada arquivo CSV e adicioná-lo à lista
for url in urls:
    df = pd.read_csv(url, sep=';', encoding='latin1')
    dataframes.append(df)

# Concatenar todos os DataFrames em um único
df = pd.concat(dataframes, ignore_index=True)

# Exibir as primeiras linhas do DataFrame consolidado
df.head()


df.tail()


df.shape


df.info()


df.dtypes





df.columns = ["ICAO_Empresa_Aérea",
              "Número_Voo", "Código_Autorização_(DI)",
              "Código_Tipo_Linha", "ICAO_Aeródromo_Origem",
              "ICAO_Aeródromo_Destino", "Partida_Prevista",
              "Partida_Real", "Chegada_Prevista",
              "Chegada_Real", "Situação_Voo",
              "Código_Justificativa", "Código_DI"]

df


# Converter colunas de datas/horários para o formato datetime corretamente
df['Partida_Prevista'] = pd.to_datetime(df['Partida_Prevista'], format='%d/%m/%Y %H:%M')
df['Partida_Real'] = pd.to_datetime(df['Partida_Real'], format='%d/%m/%Y %H:%M')
df['Chegada_Prevista'] = pd.to_datetime(df['Chegada_Prevista'], format='%d/%m/%Y %H:%M')
df['Chegada_Real'] = pd.to_datetime(df['Chegada_Real'], format='%d/%m/%Y %H:%M')


# Criar a coluna 'Atrasado' (1 se o voo atrasou mais de 15 minutos, 0 caso contrário)
df['Atrasado'] = (df['Partida_Real'] > df['Partida_Prevista'] + pd.Timedelta(minutes=15)).astype(int)


df.Atrasado.value_counts()





# Filtrar dados apenas para GOL, AZU e TAM
df = df[df['ICAO_Empresa_Aérea'].isin(['GOL', 'AZU', 'TAM'])]
df





print("Voos Nacionais:",df.ICAO_Aeródromo_Destino.value_counts())
df.ICAO_Empresa_Aérea.value_counts()





# Desconsiderar a Coluna "Código Justificativa"
df = df.drop(columns=['Código_Justificativa'])
df





# Calcular e visualizar a taxa de pontualidade
df['Pontualidade'] = 1 - (df['Atrasado'].sum() / len(df))


# Calcular o Indicador de Pontualidade
# Calcular a quantidade de voos realizados e atrasados
voos_realizados = len(df)
voos_atrasados = df['Atrasado'].sum()

# Calcular a taxa de pontualidade
pontualidade = 1 - (voos_atrasados / voos_realizados)
print(f"Taxa de Pontualidade: {pontualidade:.2%}")


# Classificar Voos como Pontual ou Atrasado
# Criar a coluna 'Atrasado' (1 se o voo atrasou mais de 15 minutos, 0 caso contrário)
df['Atrasado'] = (df['Partida_Real'] > df['Partida_Prevista'] + pd.Timedelta(minutes=15)).astype(int)
df











df['Partida_Prevista'] = pd.to_datetime(df['Partida_Prevista'])
df['Partida_Real'] = pd.to_datetime(df['Partida_Real'])
df['Chegada_Prevista'] = pd.to_datetime(df['Chegada_Prevista'])
df['Chegada_Real'] = pd.to_datetime(df['Chegada_Real'])

# Coluna para o Mês Extraia o mês da coluna de data para uma análise mês a mês.
df['Mês'] = df['Partida_Prevista'].dt.month

# Filtrar os Dados de 2018 Para garantir que estamos analisando apenas o ano de 2018
df_2018 = df[df['Partida_Prevista'].dt.year == 2018]

# Calcular Pontualidade por Companhia Aérea
df_2018['Atrasado'] = (df_2018['Partida_Real'] > df_2018['Partida_Prevista'] + pd.Timedelta(minutes=15)).astype(int)

# Agrupar por Companhia Aérea e Mês para Analisar a Pontualidade
pontualidade_mes = df_2018.groupby(['ICAO_Empresa_Aérea', 'Mês'])['Atrasado'].mean().reset_index()


# Plotar a Pontualidade da GOL e Concorrentes (Mês a Mês)
plt.figure(figsize=(14, 8))
sns.lineplot(data=pontualidade_mes, x='Mês', y='Atrasado', hue='ICAO_Empresa_Aérea', marker='o')
plt.title('Pontualidade Mês a Mês (2018) - Comparação GOL vs Concorrentes')
plt.xlabel('Mês')
plt.ylabel('Taxa de Atraso (média)')
plt.xticks(range(1, 13))
plt.legend(title='Companhia Aérea')
plt.tight_layout()
plt.show()








pontualidade_por_empresa = df.groupby('ICAO_Empresa_Aérea')['Atrasado'].mean()
pontualidade_por_empresa = 1 - pontualidade_por_empresa

plt.figure(figsize=(8, 5))
sns.barplot(x=pontualidade_por_empresa.index, y=pontualidade_por_empresa.values)
plt.title('Taxa de Pontualidade por Companhia Aérea')
plt.xlabel('Companhia Aérea')
plt.ylabel('Taxa de Pontualidade')
plt.show()


# Calcular a quantidade de voos realizados
voos_realizados = len(df)

# Calcular a quantidade de voos atrasados
voos_atrasados = df['Atrasado'].sum()

# Calcular o indicador de pontualidade
pontualidade = 1 - (voos_atrasados / voos_realizados)

# Exibir o resultado
print(f"Indicador de Pontualidade: {pontualidade:.2%}")


# Verificar a distribuição das companhias aéreas
print(df['ICAO_Empresa_Aérea'].value_counts())


# Visualizar Distribuições

# Verificar a proporção de voos atrasados por companhia aérea
atrasos_por_empresa = df.groupby('ICAO_Empresa_Aérea')['Atrasado'].mean()

plt.figure(figsize=(8, 5))
sns.barplot(x=atrasos_por_empresa.index, y=atrasos_por_empresa.values)
plt.title('Proporção de Voos Atrasados por Companhia Aérea')
plt.xlabel('Companhia Aérea')
plt.ylabel('Proporção de Atrasos')
plt.show()


# Extrair a hora da 'Partida_Prevista'
df['Hora_Partida_Prevista'] = df['Partida_Prevista'].dt.hour

# Visualizar a distribuição de atrasos por hora
plt.figure(figsize=(10, 6))
sns.lineplot(x='Hora_Partida_Prevista', y='Atrasado', data=df)
plt.title('Proporção de Atrasos por Hora de Partida')
plt.xlabel('Hora de Partida (24h)')
plt.ylabel('Proporção de Atrasos')
plt.show()


# Verificar a distribuição da 'Situação_Voo'
situacao_voo_counts = df['Situação_Voo'].value_counts()

# Visualizar a distribuição das situações de voo
plt.figure(figsize=(8, 5))
sns.barplot(x=situacao_voo_counts.index, y=situacao_voo_counts.values)
plt.title('Distribuição das Situações de Voo')
plt.xlabel('Situação do Voo')
plt.ylabel('Número de Voos')
plt.xticks(rotation=45)
plt.show()


# Analisar os aeroportos com maior número de atrasos
atrasos_por_aeroporto_origem = df.groupby('ICAO_Aeródromo_Origem')['Atrasado'].mean().sort_values(ascending=False)
atrasos_por_aeroporto_destino = df.groupby('ICAO_Aeródromo_Destino')['Atrasado'].mean().sort_values(ascending=False)

# Visualizar os aeroportos de origem com mais atrasos
plt.figure(figsize=(10, 5))
sns.barplot(x=atrasos_por_aeroporto_origem.index[:10], y=atrasos_por_aeroporto_origem.values[:10])
plt.title('Top 10 Aeroportos de Origem com Maior Proporção de Atrasos')
plt.xlabel('Aeroporto de Origem')
plt.ylabel('Proporção de Atrasos')
plt.xticks(rotation=45)
plt.show()


# Visualizar os aeroportos de destino com mais atrasos
plt.figure(figsize=(10, 5))
sns.barplot(x=atrasos_por_aeroporto_destino.index[:10], y=atrasos_por_aeroporto_destino.values[:10])
plt.title('Top 10 Aeroportos de Destino com Maior Proporção de Atrasos')
plt.xlabel('Aeroporto de Destino')
plt.ylabel('Proporção de Atrasos')
plt.xticks(rotation=45)
plt.show()


## Análise Temporal

# Criar colunas para mês e dia da semana
df['Mês'] = df['Partida_Prevista'].dt.month
df['Dia_da_Semana'] = df['Partida_Prevista'].dt.day_name()

# Analisar a proporção de atrasos por mês
atrasos_por_mes = df.groupby('Mês')['Atrasado'].mean()

plt.figure(figsize=(8, 5))
sns.lineplot(x=atrasos_por_mes.index, y=atrasos_por_mes.values)
plt.title('Proporção de Atrasos por Mês')
plt.xlabel('Mês')
plt.ylabel('Proporção de Atrasos')
plt.show()


# Analisar a proporção de atrasos por dia da semana
atrasos_por_dia = df.groupby('Dia_da_Semana')['Atrasado'].mean().reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])

plt.figure(figsize=(8, 5))
sns.barplot(x=atrasos_por_dia.index, y=atrasos_por_dia.values)
plt.title('Proporção de Atrasos por Dia da Semana')
plt.xlabel('Dia da Semana')
plt.ylabel('Proporção de Atrasos')
plt.xticks(rotation=45)
plt.show()


# Visualizar a distribuição por tipo de linha
plt.figure(figsize=(8, 5))
sns.countplot(data=df, x='Código_Tipo_Linha')
plt.title('Distribuição de Voos por Tipo de Linha')
plt.xlabel('Tipo de Linha')
plt.ylabel('Número de Voos')
plt.show()





## Análise de Atrasos por Aeroporto de Origem e Destino

# Atrasos por aeroporto de origem
atrasos_por_origem = df.groupby('ICAO_Aeródromo_Origem')['Atrasado'].mean().sort_values(ascending=False)
print("Top aeroportos de origem com maior proporção de atrasos:")
print(atrasos_por_origem.head(10))

# Atrasos por aeroporto de destino
atrasos_por_destino = df.groupby('ICAO_Aeródromo_Destino')['Atrasado'].mean().sort_values(ascending=False)
print("\nTop aeroportos de destino com maior proporção de atrasos:")
print(atrasos_por_destino.head(10))


## Análise de Atrasos por Situação do Voo

# Visualizar atrasos por situação do voo
plt.figure(figsize=(10, 5))
sns.barplot(x='Situação_Voo', y='Atrasado', data=df)
plt.title('Proporção de Atrasos por Situação do Voo')
plt.xlabel('Situação do Voo')
plt.ylabel('Proporção de Atrasos')
plt.show()


# Extrair o dia da semana e o mês da Partida_Prevista
df['Dia_Semana'] = df['Partida_Prevista'].dt.day_name()
df['Mês'] = df['Partida_Prevista'].dt.month_name()

# Visualizar atrasos por dia da semana
plt.figure(figsize=(10, 5))
sns.barplot(x='Dia_Semana', y='Atrasado', data=df, order=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])
plt.title('Proporção de Atrasos por Dia da Semana')
plt.xlabel('Dia da Semana')
plt.ylabel('Proporção de Atrasos')
plt.show()


# Visualizar atrasos por mês
plt.figure(figsize=(10, 5))
sns.barplot(x='Mês', y='Atrasado', data=df, order=['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'])
plt.title('Proporção de Atrasos por Mês')
plt.xlabel('Mês')
plt.ylabel('Proporção de Atrasos')
plt.show()





df.shape


# Verificar a quantidade de valores ausentes em cada coluna
print(df.isnull().sum())


# Excluir as colunas especificadas
df = df.drop(columns=['Hora_Partida_Prevista', 'Mês', 'Dia_da_Semana', 'Dia_Semana'])

# Verificar se as colunas foram removidas
df.head()


# Exibir o DataFrame com True para valores ausentes e False para valores não ausentes
missing_data = df.isnull()
missing_data


# Remover linhas com valores nulos em colunas essenciais
df = df.dropna(subset=['Partida_Prevista', 'Partida_Real', 'Chegada_Prevista', 'Chegada_Real'])

# Verificar a quantidade de valores ausentes em cada coluna
print(df.isnull().sum())


df.shape


# Preencher valores nulos com 'Desconhecido'
df['Código_Autorização_(DI)'] = df['Código_Autorização_(DI)'].fillna('Desconhecido')

# Verificar a quantidade de valores ausentes em cada coluna
print(df.isnull().sum())


# Preencher valores nulos com 'Desconhecido'
df['Código_DI'] = df['Código_DI'].fillna('Desconhecido')

# Verificar a quantidade de valores ausentes em cada coluna
print(df.isnull().sum())


# Verificar se há linhas duplicadas
duplicated_rows = df.duplicated()
print(f"Número de linhas duplicadas: {duplicated_rows.sum()}")


# Exibir as linhas duplicadas, se existirem
if duplicated_rows.sum() > 0:
    print("Linhas duplicadas:")
    print(df[duplicated_rows])


# Remover as linhas duplicadas
df = df.drop_duplicates()

# Verificar novamente se há duplicatas
print(f"Número de linhas duplicadas após remoção: {df.duplicated().sum()}")


df.head()


df.tail()


df.Atrasado.value_counts()





# Converter todos os valores na coluna para string
df['Código_Autorização_(DI)'] = df['Código_Autorização_(DI)'].astype(str)

# info dados
df.info()


df


from sklearn.preprocessing import LabelEncoder

# Inicializar o LabelEncoder
label_encoder = LabelEncoder()

# Lista das colunas categóricas
categorical_columns = ['ICAO_Empresa_Aérea',
                       'Código_Autorização_(DI)',
                       'Código_Tipo_Linha',
                       'ICAO_Aeródromo_Origem',
                       'ICAO_Aeródromo_Destino',
                       'Situação_Voo',
                       'Número_Voo',
                       'Código_DI']

# Aplicar LabelEncoder em cada coluna categórica
for col in categorical_columns:
    df[col] = label_encoder.fit_transform(df[col].astype(str))

# Visualizando label encoder
label_encoder


# Exibir o DataFrame com as colunas transformadas
df.head()








# Separar variáveis independentes (X) e a variável dependente (y)
X = df.drop('Atrasado', axis=1)  # 'Atrasado' é a variável alvo; ajuste conforme necessário
y = df['Atrasado']


# Remover colunas de data/hora de X
X = X.drop(columns=['Partida_Prevista', 'Partida_Real', 'Chegada_Prevista', 'Chegada_Real'])
X


# Verificar os tipos de dados no DataFrame X
print(X.dtypes)


# Visualizando dados x
X.shape


# Visualizando dados y
y.shape





from sklearn.model_selection import train_test_split

# Dividir em conjuntos de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Visualizando dados treino x
print("Dados treino X train", X_train.shape)

# Visualizando dados treino y
print("Dados treino y train", y_train.shape)

# Visualizando dados treino x
print("Dados treino X train", X_train.shape)

# Visualizando dados X_test
print("Dados treino X test", y_train.shape)








from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Lista para armazenar as acurácias
accuracy_values = []

# Testar valores de K de 1 a 20 (ou outro intervalo desejado)
K_range = range(1, 21)

for K in K_range:
    knn = KNeighborsClassifier(n_neighbors=K)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    accuracy_values.append(accuracy_score(y_test, y_pred))

# Encontrar o valor de K com a melhor acurácia
best_K = K_range[accuracy_values.index(max(accuracy_values))]
print(f"Melhor valor de K: {best_K}")


plt.figure(figsize=(8, 5))
plt.plot(K_range, accuracy_values, marker='o')
plt.title('Acurácia do Modelo KNN para Diferentes Valores de K')
plt.xlabel('Número de Vizinhos (K)')
plt.ylabel('Acurácia')
plt.xticks(K_range)
plt.grid(False)
plt.show()


%%time

# Importing libraries for various classification models and performance evaluation
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.metrics import accuracy_score

# 7. List of models to be evaluated
models = [

    # Naive Bayes model (good for small datasets, assumes independence between features)
    GaussianNB(),

    # Decision Tree model (simple and interpretable, prone to overfitting)
    DecisionTreeClassifier(random_state=42),

    # Random Forest (ensemble of decision trees, reduces overfitting and improves accuracy)
    RandomForestClassifier(n_estimators=100, random_state=42),

    # Logistic Regression (linear model, great for binary classification problems)
    LogisticRegression(random_state=50, max_iter=1000),

    # AdaBoost (boosting algorithm, combines weak learners to create a strong classifier)
    AdaBoostClassifier(random_state=45),

    # XGBoost (powerful gradient boosting algorithm, handles missing data well and has regularization)
    XGBClassifier(random_state=42),

    # LightGBM (another gradient boosting model optimized for speed and performance)
    LGBMClassifier(boosting_type='gbdt', bagging_fraction=0.9, learning_rate=0.05,
                   feature_fraction=0.9, bagging_freq=50, verbosity=-1,
                   verbose=50),

    # K-Nearest Neighbors (instance-based learning, predicts class based on closest neighbors)
    KNeighborsClassifier(n_neighbors=best_K, metric='minkowski', p=2),

    # Gradient Boosting (boosting technique that builds models sequentially to reduce errors)
    GradientBoostingClassifier(random_state=42)
]

# 10. Loop through each model and evaluate performance on training and test data
for i, model in enumerate(models):

    # Train the model on the training dataset
    model.fit(X_train, y_train)

    # Calculate the training accuracy
    train_accuracy = accuracy_score(y_train, model.predict(X_train))

    # Calculate the testing accuracy
    test_accuracy = accuracy_score(y_test, model.predict(X_test))

    # Print the model's name and accuracy on training and testing datasets
    print("-----------------")
    print()
    print(f"Model {i+1}: {type(model).__name__}")
    print(f"Training Accuracy: {train_accuracy}")
    print(f"Testing Accuracy: {test_accuracy}")
    print("-----------------")
    print()


models = {"Random Forest": RandomForestClassifier(),
          "Logistic Regression": LogisticRegression(),
          "Decision Tree": DecisionTreeClassifier()}

# Now your loop will work correctly
# Get the feature names
feature_names = X_train.columns

# Iterate over the models
for model_name, model in models.items():
    print(f"Training {model_name}...")

    # Train the model
    model.fit(X_train, y_train)

    # Plot feature importance for models that support it
    if hasattr(model, 'feature_importances_'):

        # Tree-based models
        importance = model.feature_importances_
        indices = np.argsort(importance)[::-1]

        # Plot
        plt.figure(figsize=(10, 6))
        plt.title(f"Feature Importance for {model_name}")
        plt.bar(range(X_train.shape[1]), importance[indices], align="center")
        plt.xticks(range(X_train.shape[1]), feature_names[indices], rotation=90)
        plt.tight_layout()
        plt.show()

    elif model_name == "Logistic Regression":

        # For Logistic Regression, use the coefficients
        importance = np.abs(model.coef_[0])

        # Absolute value of the coefficients
        indices = np.argsort(importance)[::-1]

        # Plot
        plt.figure(figsize=(10, 6))
        plt.title(f"Feature Importance for {model_name}")
        plt.bar(range(X_train.shape[1]), importance[indices], align="center")
        plt.xticks(range(X_train.shape[1]), feature_names[indices], rotation=90)
        plt.tight_layout()
        plt.show()

    else:
        print(f"Feature importance not available for {model_name}")

    print("-" * 60)


from sklearn.metrics import confusion_matrix

# Lista de modelos a serem avaliados
models = [
    ("Naive Bayes", GaussianNB()),
    ("Decision Tree", DecisionTreeClassifier(random_state=42)),
    ("Random Forest", RandomForestClassifier(n_estimators=100, random_state=42)),
    ("Logistic Regression", LogisticRegression(random_state=50, max_iter=1000)),
    ("AdaBoost", AdaBoostClassifier(random_state=45)),
    ("XGBoost", XGBClassifier(random_state=42)),
    ("LightGBM", LGBMClassifier(boosting_type='gbdt', bagging_fraction=0.9, learning_rate=0.05, feature_fraction=0.9, bagging_freq=50, verbosity=-1)),
    ("K-Nearest Neighbors", KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)),
    ("Gradient Boosting", GradientBoostingClassifier(random_state=42))
]

# Iterar sobre os modelos e plotar a matriz de confusão para cada um
for model_name, model in models:
    print(f"Training {model_name}...")

    # Treinar o modelo com o conjunto de dados
    model.fit(X_train, y_train)

    # Fazer previsões no conjunto de teste
    y_pred = model.predict(X_test)

    # Calcular a matriz de confusão
    cm = confusion_matrix(y_test, y_pred)

    # Plotar a matriz de confusão com a legenda
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
    plt.title(f"Confusion Matrix for {model_name}")
    plt.xlabel("Predicted Labels")
    plt.ylabel("True Labels")

    # Adicionar legenda para as classes
    plt.xticks([0.5, 1.5], ["0: Não Atrasado", "1: Atrasado"])
    plt.yticks([0.5, 1.5], ["0: Não Atrasado", "1: Atrasado"], rotation=0)

    plt.tight_layout()
    plt.show()

    print("-" * 60)



from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import RocCurveDisplay

# Define the models in a dictionary
models = {"Naive Bayes": GaussianNB(),
          "Decision Tree": DecisionTreeClassifier(random_state=42),
          "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
          "Logistic Regression": LogisticRegression(random_state=50, max_iter=1000),
          "AdaBoost": AdaBoostClassifier(random_state=45),
          "XGBoost": XGBClassifier(random_state=42),
          "LightGBM": LGBMClassifier(boosting_type='gbdt', bagging_fraction=0.9, learning_rate=0.05, feature_fraction=0.9, bagging_freq=50, verbosity=-1),
          "K-Nearest Neighbors": KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2),
          "Gradient Boosting": GradientBoostingClassifier(random_state=42)
          }


# Calcular as probabilidades para a classe positiva (1)
y_prob = model.predict_proba(X_test)[:, 1]  # Use apenas a probabilidade da classe 1

# Iterar sobre cada modelo no dicionário
for model_name, model in models.items():
    print(f"Training {model_name}...")

    # Treinar o modelo
    model.fit(X_train, y_train)

    # Calcular as probabilidades para a classe positiva (1)
    if hasattr(model, "predict_proba"):
        y_prob = model.predict_proba(X_test)[:, 1]  # Probabilidade para a classe positiva
    else:
        y_prob = model.decision_function(X_test)
        y_prob = (y_prob - y_prob.min()) / (y_prob.max() - y_prob.min())  # Normalizar para [0, 1]

    # Calcular a curva ROC e a AUC
    fpr, tpr, _ = roc_curve(y_test, y_prob)
    roc_auc = auc(fpr, tpr)

    # Plotar a curva ROC para este modelo
    plt.figure(figsize=(10, 8))
    plt.plot(fpr, tpr, color='blue', label=f"AUC = {roc_auc:.2f}")
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')  # Linha de adivinhação aleatória
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title(f"ROC Curve for {model_name}")
    plt.legend(loc="lower right")
    plt.show()


from sklearn.metrics import roc_auc_score, f1_score

# Define the models in a dictionary
models = {
    "Naive Bayes": GaussianNB(),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "Logistic Regression": LogisticRegression(random_state=50, max_iter=1000),
    "AdaBoost": AdaBoostClassifier(random_state=45),
    "XGBoost": XGBClassifier(random_state=42),
    "LightGBM": LGBMClassifier(boosting_type='gbdt', bagging_fraction=0.9, learning_rate=0.05, feature_fraction=0.9, bagging_freq=50, verbosity=-1),
    "K-Nearest Neighbors": KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42)
}

# Initialize an empty list to store metrics
metrics_list = []

# Set a custom threshold
threshold = 0.6

# Iterate over the models
for model_name, model in models.items():
    print(f"Training {model_name}...")

    # Train the model
    model.fit(X_train, y_train)

    # Get predicted probabilities for the positive class (1)
    if hasattr(model, "predict_proba"):
        y_prob = model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class
    else:
        y_prob = model.decision_function(X_test)
        y_prob = (y_prob - y_prob.min()) / (y_prob.max() - y_prob.min())  # Normalize to [0, 1]

    # Calculate AUC-ROC for binary classification
    auc_roc = roc_auc_score(y_test, y_prob)

    # Apply custom threshold to get binary predictions
    y_pred_threshold = (y_prob >= threshold).astype(int)

    # Calculate F1-Score with custom threshold
    f1_with_threshold = f1_score(y_test, y_pred_threshold)

    # Append metrics for this model
    metrics_list.append({'Model': model_name, 'AUC-ROC': auc_roc, 'F1-Score with Threshold': f1_with_threshold})

# Convert metrics list to a DataFrame
metrics_df = pd.DataFrame(metrics_list)

# Find the best model based on AUC-ROC
best_model_idx = metrics_df['AUC-ROC'].idxmax()

# Function to highlight the best model row in yellow
def highlight_best(s):
    return ['background-color: yellow' if s.name == best_model_idx else '' for _ in s]

# Apply the highlight function to the DataFrame
styled_df = metrics_df.style.apply(highlight_best, axis=1)
styled_df





# Verificando driver da GPU
!nvidia-smi


import tensorflow as tf
import tensorflow as tf
from tensorflow import keras

print("GPUs disponíveis:", len(tf.config.list_physical_devices('GPU')))
print(tf.__version__)


# Verificar se a GPU está disponível
if tf.config.list_physical_devices('GPU'):
    print("GPU disponível")
else:
    print("GPU não disponível, certifique-se de que você tem acesso a uma GPU")


# Check if a GPU is available

import torch
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")


# Print the summary of CUDA memory usage for the specified device

#import torch
#print(torch.cuda.memory_summary(device=torch.device('cuda')))


import tensorflow as tf
from tensorflow import keras

# Definir o número de classes únicas na sua variável alvo
num_classes = len(np.unique(y_train))

# Lista de modelos com duas redes neurais
models = [

    # Rede Neural Simples
     {"name": "Simple Neural Network",
      "model": keras.Sequential([
      keras.layers.Dense(64, input_shape=(X_train.shape[1],), activation='relu'),
      keras.layers.Dense(32, activation='relu'),
      keras.layers.Dense(1, activation='sigmoid')])},

    # Rede Neural Profunda
    {"name": "Deep Neural Network",
     "model": keras.Sequential([
         keras.layers.Dense(128, input_shape=(X_train.shape[1],), activation='relu'),
         keras.layers.Dense(64, activation='relu'),
         keras.layers.Dense(32, activation='relu'),
         keras.layers.Dense(1, activation='sigmoid')])}
]


%%time

# Iterar sobre os modelos e gerar o relatório de classificação
for model_info in models:
    model_name = model_info["name"]
    model = model_info["model"]

    # Compilar o modelo
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    # Treinar o modelo
    print(f"Training {model_name}...")

    history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2)

    print(f"Finished training {model_name}\n")


# Iterar sobre os modelos e treiná-los
for model_info in models:
    model_name = model_info["name"]
    model = model_info["model"]

    # Compilar o modelo
    if model_info.get("multi_class"):
        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    else:
        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    # Pré-processar os dados, se necessário
    if model_info.get("reshape"):
        X_train_mod = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
        X_test_mod = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))
    else:
        X_train_mod = X_train
        X_test_mod = X_test

    # Plotar o histórico de treinamento
    plt.figure(figsize=(12, 5))

    # Plotar a precisão
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.title(f'Accuracy Over Epochs for {model_name}')
    plt.legend()

    # Plotar a perda
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title(f'Loss Over Epochs for {model_name}')
    plt.legend()

    plt.tight_layout()
    plt.show()


# Lista para armazenar as métricas de acurácia
accuracy_list = []

# Iterar sobre os modelos, treinar cada um e calcular a acurácia
for model_info in models:
    model_name = model_info["name"]
    model = model_info["model"]

    # Compilar o modelo
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    # Avaliar o modelo no conjunto de teste
    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)

    # Adicionar a métrica de acurácia ao accuracy_list
    accuracy_list.append({
        "Model": model_name,
        "Accuracy": accuracy
    })

# Criar um DataFrame com as métricas de acurácia
accuracy_df = pd.DataFrame(accuracy_list)

# Mostrar o DataFrame
accuracy_df


## Matriz de confusão Rede Neural

# Iterar sobre os modelos e treiná-los
for model_info in models:
    model_name = model_info["name"]
    model = model_info["model"]

    # Compilar o modelo
    if model_info.get("multi_class"):
        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    else:
        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    # Pré-processar os dados, se necessário
    if model_info.get("reshape"):
        X_train_mod = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
        X_test_mod = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))
    else:
        X_train_mod = X_train
        X_test_mod = X_test

    # Fazer previsões no conjunto de teste
    y_pred = (model.predict(X_test_mod) > 0.5).astype("int32")

    # Calcular a matriz de confusão
    cm = confusion_matrix(y_test, y_pred)

    # Plotar a matriz de confusão
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
    plt.title(f"Confusion Matrix for {model_name}")
    plt.xlabel("Predicted Labels")
    plt.ylabel("True Labels")
    plt.xticks([0.5, 1.5], ["0: Não Atrasado", "1: Atrasado"])
    plt.yticks([0.5, 1.5], ["0: Não Atrasado", "1: Atrasado"], rotation=0)
    plt.tight_layout()
    plt.show()

    print("-" * 60)



## Classification report
from sklearn.metrics import classification_report

# Iterar sobre os modelos e gerar o relatório de classificação
for model_info in models:
    model_name = model_info["name"]
    model = model_info["model"]

    # Compilar o modelo
    if model_info.get("multi_class"):
        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    else:
        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    # Pré-processar os dados, se necessário
    if model_info.get("reshape"):
        X_train_mod = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
        X_test_mod = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))
    else:
        X_train_mod = X_train
        X_test_mod = X_test

    # Fazer previsões no conjunto de teste
    if model_info.get("multi_class"):
        y_pred = np.argmax(model.predict(X_test_mod), axis=1)
        y_true = np.argmax(y_test, axis=1)
    else:
        y_pred = (model.predict(X_test_mod) > 0.5).astype("int32").flatten()
        y_true = y_test

    # Gerar o relatório de classificação
    print(f"Classification Report for {model_name}:")
    print(classification_report(y_true, y_pred))
    print("-" * 60)





import tensorflow as tf
from tensorflow import keras
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Avaliar modelos de machine learning
ml_models = [('Naive Bayes', GaussianNB()),
             ('Decision Tree', DecisionTreeClassifier(random_state=42)),
             ('Random Forest', RandomForestClassifier(n_estimators=100, random_state=42)),
             ('Logistic Regression', LogisticRegression(random_state=50, max_iter=1000)),
             ('AdaBoost', AdaBoostClassifier(random_state=45)),
             ('XGBoost', XGBClassifier(random_state=42)),
             ('LightGBM', LGBMClassifier(boosting_type='gbdt', bagging_fraction=0.9, learning_rate=0.05, feature_fraction=0.9, bagging_freq=50, verbosity=-1)),
             ('K-Nearest Neighbors', KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)),
             ('Gradient Boosting', GradientBoostingClassifier(random_state=42))]

# Lista de modelos de redes neurais
nn_models = [{"name": "Simple Neural Network",
              "model": keras.Sequential([keras.layers.Dense(64, input_shape=(X_train.shape[1],), activation='relu'),
                                         keras.layers.Dense(32, activation='relu'),
                                         keras.layers.Dense(1, activation='sigmoid')])},
             
             {"name": "Deep Neural Network",
              "model": keras.Sequential([keras.layers.Dense(128, input_shape=(X_train.shape[1],), activation='relu'),
                                         keras.layers.Dense(64, activation='relu'),
                                         keras.layers.Dense(32, activation='relu'),
                                         keras.layers.Dense(1, activation='sigmoid')])}]

# Lista para armazenar as métricas de todos os modelos
metrics_list = []

# Avaliar modelos de machine learning
for model_name, model in ml_models:
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    metrics_list.append({'Model': model_name, 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1})

# Avaliar redes neurais
for model_info in nn_models:
    model_name = model_info["name"]
    model = model_info["model"]
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    model.fit(X_train, y_train, epochs=30, batch_size=32, verbose=0, validation_split=0.2)
    y_pred = (model.predict(X_test) > 0.5).astype("int32").flatten()
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    metrics_list.append({'Model': model_name, 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1})

# Converter a lista de métricas em um DataFrame
metrics_df = pd.DataFrame(metrics_list)
best_model_idx = metrics_df['F1-Score'].idxmax()

# Função para destacar o melhor modelo
def highlight_best(s):
    return ['background-color: yellow' if s.name == best_model_idx else '' for _ in s]

# Aplicar o destaque ao DataFrame
styled_df = metrics_df.style.apply(highlight_best, axis=1)
styled_df



























